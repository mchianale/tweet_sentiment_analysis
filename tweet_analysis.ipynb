{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32c2a5e4",
   "metadata": {},
   "source": [
    "# 1. IMPORTING LIBRAIRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6252158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037ea665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f85b72ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef1f7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda0e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc40495d",
   "metadata": {},
   "source": [
    "# 2. LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "469e219f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4902eb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27481 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27481 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 858.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa97ba",
   "metadata": {},
   "source": [
    "# 3. CLEAN THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c05226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID           0\n",
       "text             1\n",
       "selected_text    1\n",
       "sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9746622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bfc9ef",
   "metadata": {},
   "source": [
    "# 4. GENERATE X VALUES BY SENTENCE VECTOR & TEXT NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f233d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try text or selected_text\n",
    "#it works better for 'selected_text' column\n",
    "feature_name = 'selected_text'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5c5704",
   "metadata": {},
   "source": [
    "## A. CLEAN THE SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4208e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_insult(w):\n",
    "    \"\"\" test if the word w is potentially an insult. We look if '***' until '*********' is in w \"\"\"\n",
    "    insult = ['***']\n",
    "    if insult[0] in w:\n",
    "        return True\n",
    "    for i in range(1, 7):\n",
    "        insult.append(insult[i-1]+'*')\n",
    "        if insult[i] in w:\n",
    "            return True\n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c64b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(w):\n",
    "    \"\"\" remove special character, put lower, put 'insult' \"\"\"\n",
    "    \"\"\" if you use drop_char, it will also remove single character \"\"\"\n",
    "    if test_insult(w):\n",
    "        return 'insult'\n",
    "    \n",
    "    w = w.lower()\n",
    "    new_w = \"\"\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(w):\n",
    "        if ord(w[i]) >= 97 and ord(w[i]) <= 122:\n",
    "            new_w = new_w + w[i]\n",
    "            \n",
    "        else:\n",
    "            new_w = new_w + \" \"\n",
    "            \n",
    "        i += 1\n",
    "        \n",
    "    return new_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6b91474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(s) :\n",
    "    \"\"\" clean each word of the sentence \"\"\"\n",
    "    lwords = s.split()\n",
    "    for i in range(0, len(lwords)) :\n",
    "        w = clean_words(lwords[i])\n",
    "        #if w == 'insult': print(lwords[i]) , check what it is considered like an insult, it's not perfect\n",
    "        lwords[i] = w\n",
    "       \n",
    "    \n",
    "    space = \" \"\n",
    "    s = space.join(lwords)\n",
    "  \n",
    "    if s == '' or s == ' ':\n",
    "        return None\n",
    "    \n",
    "    return space.join(lwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d5e2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean all sentence of the fetaure column and create a new column with the clean values\n",
    "df['filtered_text'] = df[feature_name].apply(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c92584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID           0\n",
       "text             0\n",
       "selected_text    0\n",
       "sentiment        0\n",
       "filtered_text    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2178096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a81815b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>i d have responded  if i were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>sooo sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>bullying me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>sons of insult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>d lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>don t force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>yay good for both of you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>but it was worth it insult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>all this flirting going on   the atg smiles  y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27479 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1                                               Sooo SAD  negative   \n",
       "2                                            bullying me  negative   \n",
       "3                                         leave me alone  negative   \n",
       "4                                          Sons of ****,  negative   \n",
       "...                                                  ...       ...   \n",
       "27476                                             d lost  negative   \n",
       "27477                                      , don`t force  negative   \n",
       "27478                          Yay good for both of you.  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral   \n",
       "\n",
       "                                           filtered_text  \n",
       "0                    i d have responded  if i were going  \n",
       "1                                               sooo sad  \n",
       "2                                            bullying me  \n",
       "3                                         leave me alone  \n",
       "4                                         sons of insult  \n",
       "...                                                  ...  \n",
       "27476                                             d lost  \n",
       "27477                                        don t force  \n",
       "27478                          yay good for both of you   \n",
       "27479                         but it was worth it insult  \n",
       "27480  all this flirting going on   the atg smiles  y...  \n",
       "\n",
       "[27479 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f218732e",
   "metadata": {},
   "source": [
    "## B. SENTENCE VECTOR WITH TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afb34287",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltext = list(df['filtered_text'])\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(ltext)\n",
    "sequences = tokenizer.texts_to_sequences(ltext)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_sequence_length = max(len(sequence) for sequence in sequences)\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e6cb16",
   "metadata": {},
   "source": [
    "# 4. CREATE SENTIMENT'S VECTOR COLUMN, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1543599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2664d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = {'positive': 0, 'negative': 1, 'neutral': 2}\n",
    "Vsentiments = np.array([sentiment_dict[s] for s in sentiments])\n",
    "Y = pd.get_dummies(Vsentiments).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2384d254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b117cc",
   "metadata": {},
   "source": [
    "# 5. FIRST MODEL FITTING AND PREDICTING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1817e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2 , random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d72572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_sequence_length))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e4b4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6497ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size depends of your GPU, CPU:\n",
    "batch_size = 32 \n",
    "#increase epochs increase time execution !!\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb8c4f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "687/687 [==============================] - 76s 100ms/step - loss: 0.5588 - accuracy: 0.7757 - val_loss: 0.4335 - val_accuracy: 0.8326\n",
      "Epoch 2/5\n",
      "687/687 [==============================] - 68s 99ms/step - loss: 0.3247 - accuracy: 0.8857 - val_loss: 0.4449 - val_accuracy: 0.8372\n",
      "Epoch 3/5\n",
      "687/687 [==============================] - 71s 104ms/step - loss: 0.2364 - accuracy: 0.9196 - val_loss: 0.4566 - val_accuracy: 0.8328\n",
      "Epoch 4/5\n",
      "687/687 [==============================] - 71s 104ms/step - loss: 0.1860 - accuracy: 0.9361 - val_loss: 0.5076 - val_accuracy: 0.8352\n",
      "Epoch 5/5\n",
      "687/687 [==============================] - 69s 101ms/step - loss: 0.1494 - accuracy: 0.9492 - val_loss: 0.5330 - val_accuracy: 0.8284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18871de3fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3da42e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 4s 23ms/step - loss: 0.5330 - accuracy: 0.8284\n",
      "first loss : 53.30%, first accuracy : 82.84%\n"
     ]
    }
   ],
   "source": [
    "first_loss, first_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"first loss : {:.2f}%, first accuracy : {:.2f}%\". format(first_loss*100,first_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fcf856",
   "metadata": {},
   "source": [
    "# 6. MODEL OPTIMIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d178f40",
   "metadata": {},
   "source": [
    "## A. FIND THE BEST PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5a83c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minimize size of train value to get time\n",
    "k = 12\n",
    "small_X_train = X_train[0:len(X_train)//k]\n",
    "small_y_train = y_train[0:len(y_train)//k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0e2b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(hidden_nodes=128, dropout_rate=0.2, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, input_length=max_sequence_length))\n",
    "    model.add(LSTM(hidden_nodes, dropout=dropout_rate, recurrent_dropout=0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "427a538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = [0.2, 0.3, 0.5]   \n",
    "hidden_nodes = [32, 64, 128]  \n",
    "optimizer = ['adam']\n",
    "batch_size = [32,16,64]  \n",
    "epochs = [1,2] #take a lot of time if you add or increase values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46ba3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_lstm_model, batch_size=batch_size, verbose=0, dropout_rate=dropout_rate, hidden_nodes = hidden_nodes,optimizer=optimizer, epochs=epochs)\n",
    "param_grid = {\n",
    "    'hidden_nodes': hidden_nodes, \n",
    "    'dropout_rate': dropout_rate, \n",
    "    'optimizer': optimizer,\n",
    "    'batch_size': batch_size, \n",
    "    'epochs': epochs\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eea753af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=KerasClassifier(batch_size=[32, 16, 64], dropout_rate=[0.2, 0.3, 0.5], epochs=[1, 2], hidden_nodes=[32, 64, 128], model=&lt;function create_lstm_model at 0x0000018871D0B430&gt;, optimizer=[&#x27;adam&#x27;], verbose=0),\n",
       "             param_grid={&#x27;batch_size&#x27;: [32, 16, 64],\n",
       "                         &#x27;dropout_rate&#x27;: [0.2, 0.3, 0.5], &#x27;epochs&#x27;: [1, 2],\n",
       "                         &#x27;hidden_nodes&#x27;: [32, 64, 128], &#x27;optimizer&#x27;: [&#x27;adam&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=KerasClassifier(batch_size=[32, 16, 64], dropout_rate=[0.2, 0.3, 0.5], epochs=[1, 2], hidden_nodes=[32, 64, 128], model=&lt;function create_lstm_model at 0x0000018871D0B430&gt;, optimizer=[&#x27;adam&#x27;], verbose=0),\n",
       "             param_grid={&#x27;batch_size&#x27;: [32, 16, 64],\n",
       "                         &#x27;dropout_rate&#x27;: [0.2, 0.3, 0.5], &#x27;epochs&#x27;: [1, 2],\n",
       "                         &#x27;hidden_nodes&#x27;: [32, 64, 128], &#x27;optimizer&#x27;: [&#x27;adam&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function create_lstm_model at 0x0000018871D0B430&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=[&#x27;adam&#x27;]\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=[32, 16, 64]\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=[1, 2]\n",
       "\tdropout_rate=[0.2, 0.3, 0.5]\n",
       "\thidden_nodes=[32, 64, 128]\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function create_lstm_model at 0x0000018871D0B430&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=[&#x27;adam&#x27;]\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=[32, 16, 64]\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=[1, 2]\n",
       "\tdropout_rate=[0.2, 0.3, 0.5]\n",
       "\thidden_nodes=[32, 64, 128]\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=KerasClassifier(batch_size=[32, 16, 64], dropout_rate=[0.2, 0.3, 0.5], epochs=[1, 2], hidden_nodes=[32, 64, 128], model=<function create_lstm_model at 0x0000018871D0B430>, optimizer=['adam'], verbose=0),\n",
       "             param_grid={'batch_size': [32, 16, 64],\n",
       "                         'dropout_rate': [0.2, 0.3, 0.5], 'epochs': [1, 2],\n",
       "                         'hidden_nodes': [32, 64, 128], 'optimizer': ['adam']})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97f1c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(small_X_train,small_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75dd6a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'batch_size': 16, 'dropout_rate': 0.2, 'epochs': 2, 'hidden_nodes': 128, 'optimizer': 'adam'}\n",
      "Best score:  0.7132650049636448\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: \", grid_result.best_params_)\n",
    "print(\"Best score: \", grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10527754",
   "metadata": {},
   "source": [
    "## B. FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e985def",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best parameters\n",
    "dropout_rate = grid_result.best_params_['dropout_rate']\n",
    "hidden_nodes = grid_result.best_params_['hidden_nodes']\n",
    "optimizer = grid_result.best_params_['optimizer']\n",
    "batch_size = grid_result.best_params_['batch_size']\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08cda92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_sequence_length))\n",
    "model.add(LSTM(hidden_nodes, dropout=dropout_rate, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f65cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffe81239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1374/1374 [==============================] - 207s 149ms/step - loss: 0.5308 - accuracy: 0.7906 - val_loss: 0.4316 - val_accuracy: 0.8357\n",
      "Epoch 2/2\n",
      "1374/1374 [==============================] - 201s 146ms/step - loss: 0.3137 - accuracy: 0.8897 - val_loss: 0.4312 - val_accuracy: 0.8382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1880197e130>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09a7a3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 7s 42ms/step - loss: 0.4312 - accuracy: 0.8382\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9bf98ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss: 43.12%, final accuracy : 83.82%\n",
      "optimization gain : 0.98%\n"
     ]
    }
   ],
   "source": [
    "print(\"final loss: {:.2f}%, final accuracy : {:.2f}%\". format(final_loss*100,final_accuracy*100))\n",
    "print(\"optimization gain : {:.2f}%\". format(100*(final_accuracy-first_accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7afce0f",
   "metadata": {},
   "source": [
    "# 7. CONCLUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b811f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_ = tokenizer \n",
    "def predict(s):\n",
    "    \"\"\" this function is a final function to predict the sentiment of a sentence\n",
    "        but it will only use our previus vocabulary data and don't update it\"\"\"\n",
    "    sentiment = ['positive', 'negative', 'neutral']\n",
    "    #clean the sentence and create the sequence\n",
    "    new_s = clean_sentence(s)\n",
    "    if s == None:\n",
    "        return \"empty sentence\" \n",
    "    sequence = tok_.texts_to_sequences([new_s])\n",
    "    x = pad_sequences(sequence, maxlen=max_sequence_length)\n",
    "    \n",
    "    #prediction\n",
    "    prob_ = model.predict(x)\n",
    "    pos = np.argmax(prob_)\n",
    "    \n",
    "    #result\n",
    "    print(\"'{}' seems to be {}.\". format(s, sentiment[pos]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27894ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "'I love eat' seems to be positive.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "'I hate you' seems to be negative.\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "'we are sad' seems to be negative.\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "'I have to go' seems to be neutral.\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "'I really loved the movie, it was fantastic!' seems to be positive.\n"
     ]
    }
   ],
   "source": [
    "#some test\n",
    "predict(\"I love eat\")  \n",
    "predict(\"I hate you\")  \n",
    "predict(\"we are sad\")\n",
    "predict(\"I have to go\")\n",
    "predict(\"I really loved the movie, it was fantastic!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
